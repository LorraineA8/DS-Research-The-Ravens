{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# __TEAM RAVENS__\n",
        "| __Name__ | __Registration Number__ | __Access Number__ | __Role__ |\n",
        "|------|---------------------|---------------|----------|\n",
        "|Lorraine Paula Arinaitwe|M23B38/004|B20729|Model training & Streamlit Integration{Notebook 2&4}|\n",
        "|Rugogamu Noela|S23B38/016|B22775|xAI & Fairness(Notebook 3)|\n",
        "|Ssendi Aloysious Malon|S23B38/002|B21258|Data Understanding and Cleaning(Notebook 1)|\n",
        "# Notebook 4: Streamlit Integration Test\n",
        "\n",
        "## Objective\n",
        "This notebook tests the integration of our trained model with Streamlit components:\n",
        "1. Load the saved model\n",
        "2. Test sample predictions\n",
        "3. Test SHAP explanations\n",
        "4. Verify all components work correctly before deployment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Model and Metadata\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optional: Diagnostic check for LightGBM and other ML libraries\n",
        "# Run this cell if you encounter DLL or import errors\n",
        "print(\"=\" * 60)\n",
        "print(\"DIAGNOSTIC: Checking ML Library Installations\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "libraries_to_check = {\n",
        "    'lightgbm': 'lightgbm',\n",
        "    'xgboost': 'xgboost',\n",
        "    'sklearn': 'sklearn',\n",
        "    'joblib': 'joblib',\n",
        "    'shap': 'shap'\n",
        "}\n",
        "\n",
        "installation_issues = []\n",
        "\n",
        "for lib_name, import_name in libraries_to_check.items():\n",
        "    try:\n",
        "        __import__(import_name)\n",
        "        print(f\"✓ {lib_name}: Installed\")\n",
        "    except ImportError as e:\n",
        "        print(f\"✗ {lib_name}: NOT INSTALLED - {e}\")\n",
        "        installation_issues.append(lib_name)\n",
        "    except Exception as e:\n",
        "        error_msg = str(e)\n",
        "        if 'lightgbm' in error_msg.lower() or 'lib_lightgbm' in error_msg.lower() or 'dll' in error_msg.lower():\n",
        "            print(f\"⚠ {lib_name}: DLL ERROR - Cannot load library\")\n",
        "            print(f\"   Error: {error_msg[:100]}...\")\n",
        "            installation_issues.append(lib_name)\n",
        "            print(f\"\\n   FIX: pip uninstall lightgbm && pip install lightgbm\")\n",
        "        else:\n",
        "            print(f\"⚠ {lib_name}: ERROR - {error_msg[:100]}...\")\n",
        "            installation_issues.append(lib_name)\n",
        "\n",
        "if installation_issues:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"INSTALLATION ISSUES DETECTED\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nLibraries with issues: {', '.join(installation_issues)}\")\n",
        "    print(\"\\nRecommended fixes:\")\n",
        "    for lib in installation_issues:\n",
        "        if lib == 'lightgbm':\n",
        "            print(f\"\\n  For {lib}:\")\n",
        "            print(\"    1. pip uninstall lightgbm\")\n",
        "            print(\"    2. pip install lightgbm\")\n",
        "            print(\"    3. If that fails, try: conda install -c conda-forge lightgbm\")\n",
        "            print(\"    4. For Windows: Install Visual C++ Redistributable\")\n",
        "            print(\"       https://aka.ms/vs/17/release/vc_redist.x64.exe\")\n",
        "        else:\n",
        "            print(f\"\\n  For {lib}: pip install --upgrade {lib}\")\n",
        "    print(\"\\nAfter fixing, restart your kernel and try again.\")\n",
        "else:\n",
        "    print(\"\\n✓ All libraries are properly installed!\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MODEL LOADED\n",
            "============================================================\n",
            "Model Type: XGBoost\n",
            "Features: ['Age', 'BMI', 'BloodPressure', 'Glucose', 'DiabetesPedigreeFunction', 'PhysicalActivity', 'DietQuality', 'AlcoholUse', 'Smoking']\n",
            "Model Metrics:\n",
            "  accuracy: 0.8896\n",
            "  precision: 0.8364\n",
            "  recall: 0.8519\n",
            "  f1_score: 0.8440\n",
            "  roc_auc: 0.9678\n"
          ]
        }
      ],
      "source": [
        "# Load model\n",
        "model = joblib.load('../models/best_model_pipeline.pkl')\n",
        "\n",
        "# Load metadata\n",
        "with open('../models/model_metadata.json', 'r') as f:\n",
        "    model_metadata = json.load(f)\n",
        "\n",
        "# Load selected features\n",
        "with open('../models/selected_features.json', 'r') as f:\n",
        "    selected_features = json.load(f)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"MODEL LOADED\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Model Type: {model_metadata['model_name']}\")\n",
        "print(f\"Features: {selected_features}\")\n",
        "print(f\"Model Metrics:\")\n",
        "for metric, value in model_metadata['metrics'].items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Test Sample Prediction (Assuming the worst patient data possible)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SAMPLE PREDICTION TEST\n",
            "============================================================\n",
            "\n",
            "Sample Input:\n",
            " Age  BMI  BloodPressure  Glucose  DiabetesPedigreeFunction  PhysicalActivity  DietQuality  AlcoholUse  Smoking\n",
            " 100   60            120      300                       2.4                 0            0           2        2\n",
            "\n",
            "Prediction Results:\n",
            "  Probability (No Diabetes): 0.0442 (4.42%)\n",
            "  Probability (Diabetes): 0.9558 (95.58%)\n",
            "  Predicted Class: Diabetes\n",
            "  Risk Level: High\n"
          ]
        }
      ],
      "source": [
        "# Create a sample input (example patient data)\n",
        "# This simulates what a user would input in the Streamlit app\n",
        "sample_input = pd.DataFrame({\n",
        "    'Age': [100],\n",
        "    'BMI': [60],\n",
        "    'BloodPressure': [120],\n",
        "    'Glucose': [300],\n",
        "    'DiabetesPedigreeFunction': [2.4],\n",
        "    'PhysicalActivity': [0],\n",
        "    'DietQuality': [0],\n",
        "    'AlcoholUse': [2],\n",
        "    'Smoking': [2]\n",
        "})\n",
        "\n",
        "# Ensure all selected features are present\n",
        "for feature in selected_features:\n",
        "    if feature not in sample_input.columns:\n",
        "        # Add missing feature with a default value\n",
        "        sample_input[feature] = [0]  # You may want to use median or mean from training data\n",
        "\n",
        "# Reorder columns to match training data\n",
        "sample_input = sample_input[selected_features]\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"SAMPLE PREDICTION TEST\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nSample Input:\")\n",
        "print(sample_input.to_string(index=False))\n",
        "\n",
        "# Make prediction\n",
        "prediction_proba = model.predict_proba(sample_input)[0]\n",
        "prediction_class = model.predict(sample_input)[0]\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"  Probability (No Diabetes): {prediction_proba[0]:.4f} ({prediction_proba[0]*100:.2f}%)\")\n",
        "print(f\"  Probability (Diabetes): {prediction_proba[1]:.4f} ({prediction_proba[1]*100:.2f}%)\")\n",
        "print(f\"  Predicted Class: {'Diabetes' if prediction_class == 1 else 'No Diabetes'}\")\n",
        "print(f\"  Risk Level: {'High' if prediction_proba[1] > 0.7 else 'Medium' if prediction_proba[1] > 0.5 else 'Low'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2: Test Sample Prediction (Assuming the best patient data possible)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SAMPLE PREDICTION TEST\n",
            "============================================================\n",
            "\n",
            "Sample Input:\n",
            " Age  BMI  BloodPressure  Glucose  DiabetesPedigreeFunction  PhysicalActivity  DietQuality  AlcoholUse  Smoking\n",
            "  20   30             90      120                       0.2                 2            2           0        0\n",
            "\n",
            "Prediction Results:\n",
            "  Probability (No Diabetes): 0.9996 (99.96%)\n",
            "  Probability (Diabetes): 0.0004 (0.04%)\n",
            "  Predicted Class: No Diabetes\n",
            "  Risk Level: Low\n"
          ]
        }
      ],
      "source": [
        "# Create a sample input (example patient data)\n",
        "# This simulates what a user would input in the Streamlit app\n",
        "sample_input = pd.DataFrame({\n",
        "    'Age': [20],\n",
        "    'BMI': [30],\n",
        "    'BloodPressure': [90],\n",
        "    'Glucose': [120],\n",
        "    'DiabetesPedigreeFunction': [0.2],\n",
        "    'PhysicalActivity': [2],\n",
        "    'DietQuality': [2],\n",
        "    'AlcoholUse': [0],\n",
        "    'Smoking': [0]\n",
        "})\n",
        "\n",
        "# Ensure all selected features are present\n",
        "for feature in selected_features:\n",
        "    if feature not in sample_input.columns:\n",
        "        # Add missing feature with a default value\n",
        "        sample_input[feature] = [0]  # You may want to use median or mean from training data\n",
        "\n",
        "# Reorder columns to match training data\n",
        "sample_input = sample_input[selected_features]\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"SAMPLE PREDICTION TEST\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nSample Input:\")\n",
        "print(sample_input.to_string(index=False))\n",
        "\n",
        "# Make prediction\n",
        "prediction_proba = model.predict_proba(sample_input)[0]\n",
        "prediction_class = model.predict(sample_input)[0]\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"  Probability (No Diabetes): {prediction_proba[0]:.4f} ({prediction_proba[0]*100:.2f}%)\")\n",
        "print(f\"  Probability (Diabetes): {prediction_proba[1]:.4f} ({prediction_proba[1]*100:.2f}%)\")\n",
        "print(f\"  Predicted Class: {'Diabetes' if prediction_class == 1 else 'No Diabetes'}\")\n",
        "print(f\"  Risk Level: {'High' if prediction_proba[1] > 0.7 else 'Medium' if prediction_proba[1] > 0.5 else 'Low'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Test SHAP Explanation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SHAP explainer loaded successfully\n",
            "SHAP values shape: (1, 9)\n",
            "SHAP values: [[-0.6205177  -0.4708237  -1.051346   -0.1977508  -0.3701405  -2.1423838\n",
            "  -1.6691223  -0.40114337 -0.32011282]]\n",
            "\n",
            "SHAP explainer test successful!\n"
          ]
        }
      ],
      "source": [
        "# Try to load SHAP explainer\n",
        "try:\n",
        "    explainer_data = joblib.load('../models/shap_explainer.pkl')\n",
        "    \n",
        "    # Check if it's a direct explainer or data dict\n",
        "    if isinstance(explainer_data, dict) and 'explainer_type' in explainer_data:\n",
        "        print(\"SHAP explainer data loaded (will be recreated in Streamlit)\")\n",
        "        print(f\"Explainer type: {explainer_data['explainer_type']}\")\n",
        "    else:\n",
        "        print(\"SHAP explainer loaded successfully\")\n",
        "        # Test SHAP values\n",
        "        shap_values = explainer_data.shap_values(sample_input)\n",
        "        if isinstance(shap_values, list):\n",
        "            shap_values = shap_values[1]\n",
        "        print(f\"SHAP values shape: {shap_values.shape}\")\n",
        "        print(f\"SHAP values: {shap_values}\")\n",
        "    \n",
        "    print(\"\\nSHAP explainer test successful!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"SHAP explainer file not found. Run Notebook 3 first.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading SHAP explainer: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Verify All Files Exist\n",
        "\n",
        "Check that all necessary files are in place for Streamlit deployment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "FILE VERIFICATION\n",
            "============================================================\n",
            "✓ Model: ../models/best_model_pipeline.pkl\n",
            "✓ Model Metadata: ../models/model_metadata.json\n",
            "✓ Selected Features: ../models/selected_features.json\n",
            "✓ SHAP Explainer: ../models/shap_explainer.pkl\n",
            "✓ SHAP Feature Importance: ../models/shap_feature_importance.json\n",
            "\n",
            "✓ All required files are present!\n",
            "Ready for Streamlit deployment.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FILE VERIFICATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "required_files = {\n",
        "    'Model': '../models/best_model_pipeline.pkl',\n",
        "    'Model Metadata': '../models/model_metadata.json',\n",
        "    'Selected Features': '../models/selected_features.json',\n",
        "    'SHAP Explainer': '../models/shap_explainer.pkl',\n",
        "    'SHAP Feature Importance': '../models/shap_feature_importance.json'\n",
        "}\n",
        "\n",
        "all_exist = True\n",
        "for name, filepath in required_files.items():\n",
        "    exists = os.path.exists(filepath)\n",
        "    status = \"✓\" if exists else \"✗\"\n",
        "    print(f\"{status} {name}: {filepath}\")\n",
        "    if not exists:\n",
        "        all_exist = False\n",
        "\n",
        "if all_exist:\n",
        "    print(\"\\n✓ All required files are present!\")\n",
        "    print(\"Ready for Streamlit deployment.\")\n",
        "else:\n",
        "    print(\"\\n✗ Some files are missing. Please run previous notebooks.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
